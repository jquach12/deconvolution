{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary packages.# Load  \n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToPILImage\n",
    "from PIL import Image\n",
    "import progressbar\n",
    "to_pil=ToPILImage()\n",
    "%matplotlib inline\n",
    "def load_image(path):\n",
    "    image = Image.open(path) #convert LA is greyscale\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Image loaded successfully\")\n",
    "    plt.axis(\"off\")\n",
    "    return image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "    preprocess = transforms.Compose([\n",
    "    transforms.Scale(28),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ])\n",
    "    image = Variable(preprocess(image).unsqueeze_(0), requires_grad=True)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU backward hook.\n",
    "\n",
    "def relu_backward_deconv_hook(module,grad_in,grad_out):\n",
    "     if isinstance(module, nn.ReLU):\n",
    "        return (torch.clamp(grad_out[0], min=0.0),)\n",
    "def Deconvolution(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,nn.ReLU):\n",
    "            m.register_backward_hook(relu_backward_deconv_hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 1\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_sz,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "classes = [i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d716198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTConvNet(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/pytorch/tutorials/blob/master/beginner_source/former_torchies/nn_tutorial.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "nn package\n",
    "==========\n",
    "We’ve redesigned the nn package, so that it’s fully integrated with\n",
    "autograd. Let's review the changes.\n",
    "**Replace containers with autograd:**\n",
    "    You no longer have to use Containers like ``ConcatTable``, or modules like\n",
    "    ``CAddTable``, or use and debug with nngraph. We will seamlessly use\n",
    "    autograd to define our neural networks. For example,\n",
    "    * ``output = nn.CAddTable():forward({input1, input2})`` simply becomes\n",
    "      ``output = input1 + input2``\n",
    "    * ``output = nn.MulConstant(0.5):forward(input)`` simply becomes\n",
    "      ``output = input * 0.5``\n",
    "**State is no longer held in the module, but in the network graph:**\n",
    "    Using recurrent networks should be simpler because of this reason. If\n",
    "    you want to create a recurrent network, simply use the same Linear layer\n",
    "    multiple times, without having to think about sharing weights.\n",
    "    .. figure:: /_static/img/torch-nn-vs-pytorch-nn.png\n",
    "       :alt: torch-nn-vs-pytorch-nn\n",
    "       torch-nn-vs-pytorch-nn\n",
    "**Simplified debugging:**\n",
    "    Debugging is intuitive using Python’s pdb debugger, and **the debugger\n",
    "    and stack traces stop at exactly where an error occurred.** What you see\n",
    "    is what you get.\n",
    "Example 1: ConvNet\n",
    "------------------\n",
    "Let’s see how to create a small ConvNet.\n",
    "All of your networks are derived from the base class ``nn.Module``:\n",
    "-  In the constructor, you declare all the layers you want to use.\n",
    "-  In the forward function, you define how your model is going to be\n",
    "   run, from input to output\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MNISTConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # this is the place where you instantiate all your modules\n",
    "        # you can later access them using the same names you've given them in\n",
    "        # here\n",
    "        super(MNISTConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)  \n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(320, 50) #320\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    # it's the forward function that defines the network structure\n",
    "    # we're accepting only a single input in here, but if you want,\n",
    "    # feel free to use more\n",
    "    def forward(self, input):\n",
    "        x = self.pool1(F.relu(self.conv1(input)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "\n",
    "        # in your model definition you can go full crazy and use arbitrary\n",
    "        # python code to define your model structure\n",
    "        # all these are perfectly legal, and will be handled correctly\n",
    "        # by autograd:\n",
    "        # if x.gt(0) > x.numel() / 2:\n",
    "        #      ...\n",
    "        #\n",
    "        # you can even do a loop and reuse the same module inside it\n",
    "        # modules no longer hold ephemeral state, so you can use them\n",
    "        # multiple times during your forward pass\n",
    "        # while x.norm(2) < 10:\n",
    "        #    x = self.conv1(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "###############################################################\n",
    "# Let's use the defined ConvNet now.\n",
    "# You create an instance of the class first.\n",
    "\n",
    "\n",
    "net = torch.load('/Users/silver/Desktop/ucla_medical_imaging_informatics/dl4health_notebooks/deconvolution/vmnist.pt')\n",
    "print(net)\n",
    "\n",
    "#loading weights doesnt work for some reason\n",
    "#net.load_state_dict(torch.load('/Users/silver/Desktop/ucla_medical_imaging_informatics/dl4health_notebooks/deconvolution/vmnist.pt'))\n",
    "########################################################################\n",
    "# .. note::\n",
    "#\n",
    "#     ``torch.nn`` only supports mini-batches The entire ``torch.nn``\n",
    "#     package only supports inputs that are a mini-batch of samples, and not\n",
    "#     a single sample.\n",
    "#\n",
    "#     For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
    "#     ``nSamples x nChannels x Height x Width``.\n",
    "#\n",
    "#     If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
    "#     a fake batch dimension.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 3\n",
    "losses = []\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        losses.append(running_loss)\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINTS FOR DAYS\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# The output of the ConvNet ``out`` is a ``Tensor``. We compute the loss\n",
    "# using that, and that results in ``err`` which is also a ``Tensor``.\n",
    "# Calling ``.backward`` on ``err`` hence will propagate gradients all the\n",
    "# way through the ConvNet to it’s weights\n",
    "#\n",
    "# Let's access individual layer weights and gradients:\n",
    "\n",
    "# print(\"THIS IS CONV1 WEIGHT GRAD SIZE\")\n",
    "# print(net.conv1.weight.grad.size())\n",
    "\n",
    "# print(\"THIS IS CONV1 WEIGHT GRAD\")\n",
    "# print(net.conv1.weight.grad)\n",
    "\n",
    "#'MaxPool2d' object has no attribute 'weight'\n",
    "# print(\"THIS IS POOL1 WEIGHT GRAD SIZE\")\n",
    "# print(net.pool1.weight.grad.size())\n",
    "\n",
    "# print(\"THIS IS POOL1 WEIGHT GRAD\")\n",
    "# print(net.pool1.weight.grad)\n",
    "\n",
    "\n",
    "# print(\"THIS IS CONV2 WEIGHT GRAD SIZE\")\n",
    "# print(net.conv2.weight.grad.size())\n",
    "\n",
    "# print(\"THIS IS CONV2 WEIGHT GRAD\")\n",
    "# print(net.conv2.weight.grad)\n",
    "\n",
    "# print(\"THIS IS FC1 WEIGHT GRAD SIZE\")\n",
    "# print(net.fc1.weight.grad.size())\n",
    "\n",
    "# print(\"THIS IS FC1 WEIGHT GRAD\")\n",
    "# print(net.fc1.weight.grad)\n",
    "\n",
    "# print(\"THIS IS FC2 WEIGHT GRAD SIZE\")\n",
    "# print(net.fc2.weight.grad.size())\n",
    "\n",
    "# print(\"THIS IS FC2 WEIGHT GRAD\")\n",
    "# print(net.fc2.weight.grad)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Losses over {} Epochs\".format(num_epochs))\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "torch.save(net, '/Users/silver/Desktop/ucla_medical_imaging_informatics/dl4health_notebooks/deconvolution/vmnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:      1\n",
      "None\n",
      "tensor([[  0.0980,  13.7173,   0.3599,   0.0000,   5.5825,   0.0000,\n",
      "           1.0059,   0.0000,   5.3293,   3.0258]])\n",
      "0.000552426790818572\n",
      "None\n",
      "tensor([[[[ 0.1826, -0.0590,  0.0520,  0.8085,  0.5843],\n",
      "          [ 0.1485, -0.0569, -0.0522, -0.2080, -0.0780],\n",
      "          [-0.3936, -0.2170, -0.2261, -0.2354,  0.1500],\n",
      "          [ 0.0330, -0.4463, -0.6732, -0.2379,  0.2825],\n",
      "          [ 0.2375,  0.0903,  0.1091,  0.2875,  0.0429]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6366, -0.0383, -0.0634,  0.0381,  0.0739],\n",
      "          [-0.1103, -0.8514, -0.5545,  0.2447,  0.3086],\n",
      "          [-0.1417, -0.4540,  0.9455,  0.3307,  0.0216],\n",
      "          [ 0.1778,  0.6456,  0.1598, -0.5198,  0.0695],\n",
      "          [ 0.1715, -0.1218, -0.3619, -0.3539,  0.2871]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4253,  0.2714,  0.3963, -0.0146, -0.0420],\n",
      "          [ 0.1504, -0.1263,  0.0390, -0.3207, -0.3261],\n",
      "          [ 0.1362,  0.1599, -0.0190, -0.4980, -0.2362],\n",
      "          [-0.0654, -0.0802, -0.3264, -0.1785, -0.1205],\n",
      "          [-0.6727, -0.4872,  0.0207, -0.1099, -0.0717]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3940,  0.1487, -0.0101, -0.0719, -0.0246],\n",
      "          [ 0.2028,  0.2284,  0.6929,  0.7196,  0.5503],\n",
      "          [ 0.2113, -0.2484,  0.0562,  0.1488,  0.5781],\n",
      "          [-0.0670, -0.2456, -0.5577, -0.4648, -0.0949],\n",
      "          [ 0.1917,  0.1465, -0.0135, -0.2860, -0.4803]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1251,  0.1116, -0.1474, -0.1206,  0.0704],\n",
      "          [ 0.1240, -0.0537, -0.0194, -0.0594, -0.0998],\n",
      "          [-0.1503, -0.0525,  0.0571, -0.0514,  0.0431],\n",
      "          [-0.1612,  0.0047,  0.1492,  0.0576,  0.3594],\n",
      "          [-0.1042, -0.1482,  0.2618,  0.1081,  0.1997]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0121,  0.0762,  0.1115,  0.1081,  0.0282],\n",
      "          [ 0.4319,  0.0792, -0.2523,  0.1289,  0.0292],\n",
      "          [ 0.4021, -0.1934, -0.2929, -0.0085,  0.2810],\n",
      "          [ 0.3595,  0.2267, -0.0296,  0.2087,  0.1384],\n",
      "          [ 0.2802,  0.2255, -0.0159, -0.2819, -0.1337]]],\n",
      "\n",
      "\n",
      "        [[[-0.0703, -0.2002,  0.0624,  0.3667,  0.6965],\n",
      "          [ 0.3172,  0.0896, -0.5758, -0.8261,  0.3551],\n",
      "          [ 0.1276,  0.5841, -0.6947, -0.9546, -0.1735],\n",
      "          [ 0.0956,  1.2458,  0.4624, -0.4417, -0.0300],\n",
      "          [-0.6067,  0.1082,  0.7248,  0.6712, -0.0586]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2552, -0.0486, -0.0962,  0.0098,  0.0993],\n",
      "          [-0.3362, -0.2563, -0.4234, -0.2850, -0.3429],\n",
      "          [ 0.1738, -0.3120, -0.2026, -0.2583, -0.3760],\n",
      "          [-0.0424, -0.0157, -0.1122, -0.1895,  0.4317],\n",
      "          [ 0.3087,  0.0266,  0.4156,  0.6057,  0.3341]]],\n",
      "\n",
      "\n",
      "        [[[-0.0520,  0.2043,  0.4602, -0.0683, -0.2035],\n",
      "          [-0.0786, -0.0457,  0.3338,  0.0154, -0.1196],\n",
      "          [-0.3590, -0.0135,  0.5129, -0.0839, -0.2691],\n",
      "          [-0.4397,  0.5940,  0.2642, -0.2515, -0.1227],\n",
      "          [ 0.1142,  0.4447, -0.0989, -0.3301, -0.2401]]],\n",
      "\n",
      "\n",
      "        [[[-0.0803, -0.1983, -0.0606, -0.1219,  0.3485],\n",
      "          [-0.0631, -0.3388, -0.2240,  0.2126,  0.4043],\n",
      "          [-0.0204, -0.3118, -0.2324,  0.0417,  0.4514],\n",
      "          [ 0.1551, -0.1339, -0.2711, -0.1423,  0.5585],\n",
      "          [ 0.3269, -0.0180, -0.3823, -0.5938,  0.4638]]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d7162b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(1)))\n",
    "\n",
    "#suppose i am interested in first layer\n",
    "print(net.conv1.weight.grad)\n",
    "\n",
    "outputs = net(images)#forward pass\n",
    "\n",
    "print(outputs)\n",
    "loss = criterion(outputs, labels)\n",
    "print(loss.item())\n",
    "print(net.conv1.weight.data.grad)\n",
    "print(net.conv1.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:      1\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconvolution of image given the layer and number of filters to visualize.\n",
    "\n",
    "def deconvolution(image,last_layer=1,num_filters=64):\n",
    "    \n",
    "    # Get the submodel\n",
    "    #vgg16_submodel=submodel(vgg16,last_layer)\n",
    "\n",
    "    jq_m = net\n",
    "    #jq_m = jq_m.load_state_dict(torch.load('/Users/silver/Desktop/net1_weight100ep.pt'))\n",
    "    #someLayer = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    Deconvolution(jq_m)\n",
    "    \n",
    "    #Forward pass.\n",
    "    #output=vgg16_submodel(image)\n",
    "    output = jq_m(image)\n",
    "\n",
    "    print(\"I AM OUTPUT\")\n",
    "    print(output)\n",
    "    #Zero out the existing gradient buffers.\n",
    "    jq_m.zero_grad()\n",
    "\n",
    "    gradients=[]\n",
    "    bar=progressbar.ProgressBar(max_value=num_filters)\n",
    "\n",
    "    for filter_index in range(num_filters):\n",
    "\n",
    "        #Progress indicator\n",
    "        bar.update(filter_index)\n",
    "\n",
    "        #Calculate the loss.\n",
    "        #loss=torch.max(output[0][filter_index])\n",
    "        #loss = torch.max(output[0])\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        #Backward Pass\n",
    "        x = loss.backward(retain_graph=True)\n",
    "        print(x)\n",
    "\n",
    "#         #Visualize the gradient image\n",
    "#         image.grad.data=image.grad.data-image.grad.data.min()\n",
    "#         image.grad.data/=(image.grad.data.max()-image.grad.data.min())\n",
    "#         grads=image.grad.data.squeeze(0)\n",
    "#         grads.transpose_(0,1) #don't use permute.\n",
    "#         grads.transpose_(1,2)\n",
    "#         gradients.append(grads)\n",
    "\n",
    "#     fig=plt.figure(figsize=(30,30),facecolor='black')    \n",
    "#     for i in range(int(np.sqrt(num_filters))*int(np.sqrt(num_filters))):\n",
    "#         a=fig.add_subplot(np.sqrt(num_filters),np.sqrt(num_filters), i+1)\n",
    "#         a.imshow(gradients[i])\n",
    "#         a.axis('off')\n",
    "#         plt.subplots_adjust(hspace=0.01,wspace=0.01,left=0.01,bottom=0.01)\n",
    "   # plt.savefig('/Users/silver/Desktop/deconvs/Deconvolution.jpg',facecolor=fig.get_facecolor(),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.0837,\n",
      "           -2.0837, -2.0665, -2.0837, -2.1008, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1008, -1.9980, -1.4843, -0.5253,\n",
      "            0.1083,  0.3138, -0.4568, -1.3130, -1.9809, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.0837, -1.7925, -0.5424,  1.1187,  1.6838,\n",
      "            1.8208,  1.8893,  1.6838,  0.9132, -0.8849, -1.9467, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -1.7754, -0.1657,  1.5468,  1.8722,  0.8104,\n",
      "            0.2796,  0.2453,  0.6221,  1.5810,  1.0844, -1.1075, -2.0494,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1008, -1.2959,  1.2043,  1.9235,  0.5364, -1.4843,\n",
      "           -1.9124, -1.9295, -1.6898, -0.2513,  1.2728,  0.5193, -1.6213,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.9638, -0.5424,  1.8037,  0.8961, -1.3473, -2.1008,\n",
      "           -2.1179, -2.1179, -2.1008, -1.7583, -0.4226,  0.9303, -1.2788,\n",
      "           -2.1008, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.7412,  0.3823,  1.7523, -0.3198, -2.0665, -2.1179,\n",
      "           -2.1179, -2.1179, -1.9295, -0.7137, -0.3198, -0.8164, -1.8268,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.8439, -0.0116,  1.6153, -0.3198, -1.8953, -2.0152,\n",
      "           -1.9980, -1.7583, -0.5424,  1.4612,  1.6153, -0.2513, -1.8610,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.0494, -1.0048,  1.3242,  1.3413,  0.5193,  0.0741,\n",
      "            0.2111,  0.6734,  1.6153,  2.1633,  2.1462,  0.7419, -1.6555,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -1.8097, -0.3712,  1.2043,  1.7009,  1.7694,\n",
      "            1.8550,  1.8037,  1.9920,  2.1975,  2.1633,  0.8618, -1.6213,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1008, -1.9295, -1.3987, -0.6281,  0.2796,\n",
      "            0.5193, -0.2856,  0.3138,  1.9920,  2.1804,  0.8618, -1.6213,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1008, -2.0665, -1.9980,\n",
      "           -1.9980, -2.0323, -0.8849,  1.8208,  2.1462,  0.5022, -1.7240,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -0.9363,  1.8208,  1.8208, -0.6281, -1.9980,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -0.9020,  1.8208,  1.4783, -1.2445, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.9638, -0.3712,  2.0092,  1.4612, -1.2617, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.8610, -0.0116,  2.1290,  1.4612, -1.2617, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.8439,  0.0227,  2.1462,  1.4612, -1.2617, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -1.8782, -0.0801,  2.0777,  1.0844, -1.4158, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.0323, -1.1589,  0.1254, -0.8849, -1.9467, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179],\n",
      "          [-2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179,\n",
      "           -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179, -2.1179]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silver/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12177ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Deconvolution visualization of a cat.\n",
    "\n",
    "cat=load_image(\"/Users/silver/Desktop/ucla_medical_imaging_informatics/dl4health_notebooks/deconvolution/9.png\")\n",
    "cat=preprocess_image(cat)\n",
    "\n",
    "print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 20) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I AM OUTPUT\n",
      "tensor([[  0.0000,   0.0000,   3.5581,   3.2760,  11.0078,   9.2175,\n",
      "           0.0000,   6.9982,   0.0000,  31.6782]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38ed583368b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e22fbbcd583d>\u001b[0m in \u001b[0;36mdeconvolution\u001b[0;34m(image, last_layer, num_filters)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#Visualize the gradient image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m/=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "deconvolution(cat,1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
