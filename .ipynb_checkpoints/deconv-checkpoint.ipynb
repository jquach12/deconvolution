{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = [i for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    7     3     7     2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1156355c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Convolution Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Copy the neural network from the Neural Networks section before and modify it to\n",
    "take 3-channel images (instead of 1-channel images as it was defined).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.271\n",
      "[1,  4000] loss: 0.519\n",
      "[1,  6000] loss: 0.398\n",
      "[1,  8000] loss: 0.381\n",
      "[1, 10000] loss: 0.341\n",
      "[1, 12000] loss: 0.324\n",
      "[1, 14000] loss: 0.304\n",
      "[2,  2000] loss: 0.269\n",
      "[2,  4000] loss: 0.274\n",
      "[2,  6000] loss: 0.246\n",
      "[2,  8000] loss: 0.240\n",
      "[2, 10000] loss: 0.239\n",
      "[2, 12000] loss: 0.238\n",
      "[2, 14000] loss: 0.214\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:      7     2     1     0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x115594048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/silver/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 349, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/silver/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 328, in _shutdown_workers\n",
      "    self.worker_result_queue.get()\n",
      "  File \"/Users/silver/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/silver/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 86, in rebuild_storage_filename\n",
      "    storage = cls._new_shared_filename(manager, handle, size)\n",
      "RuntimeError: Interrupted system call at /Users/soumith/minicondabuild3/conda-bld/pytorch_1524590658547/work/torch/lib/libshm/core.cpp:125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115643f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let us see what the neural network thinks these examples above are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are energies for the 10 classes.\n",
    "Higher the energy for a class, the more the network\n",
    "thinks that the image is of the particular class.\n",
    "So, let's get the index of the highest energy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:      7     3     1     0\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the network performs on the whole dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks waaay better than chance, which is 10% accuracy (randomly picking\n",
    "a class out of 10 classes).\n",
    "Seems like the network learnt something.\n",
    "\n",
    "Hmmm, what are the classes that performed well, and the classes that did\n",
    "not perform well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 96 %\n",
      "Accuracy of     1 : 97 %\n",
      "Accuracy of     2 : 90 %\n",
      "Accuracy of     3 : 93 %\n",
      "Accuracy of     4 : 94 %\n",
      "Accuracy of     5 : 92 %\n",
      "Accuracy of     6 : 94 %\n",
      "Accuracy of     7 : 96 %\n",
      "Accuracy of     8 : 94 %\n",
      "Accuracy of     9 : 89 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
